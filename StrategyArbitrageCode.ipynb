{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have MMM\n",
      "Already have ABT\n",
      "Already have ABBV\n",
      "Already have ABMD\n",
      "Already have ACN\n",
      "Already have ATVI\n",
      "Already have ADBE\n",
      "Already have AMD\n",
      "Already have AAP\n",
      "Already have AES\n",
      "Already have AFL\n",
      "Already have A\n",
      "Already have APD\n",
      "Already have AKAM\n",
      "Already have ALK\n",
      "Already have ALB\n",
      "Already have ARE\n",
      "Already have ALXN\n",
      "Already have ALGN\n",
      "Already have ALLE\n",
      "Already have LNT\n",
      "Already have ALL\n",
      "Already have GOOGL\n",
      "Already have GOOG\n",
      "Already have MO\n",
      "Already have AMZN\n",
      "Already have AMCR\n",
      "Already have AEE\n",
      "Already have AAL\n",
      "Already have AEP\n",
      "Already have AXP\n",
      "Already have AIG\n",
      "Already have AMT\n",
      "Already have AWK\n",
      "Already have AMP\n",
      "Already have ABC\n",
      "Already have AME\n",
      "Already have AMGN\n",
      "Already have APH\n",
      "Already have ADI\n",
      "Already have ANSS\n",
      "Already have ANTM\n",
      "Already have AON\n",
      "Already have AOS\n",
      "Already have APA\n",
      "Already have AIV\n",
      "Already have AAPL\n",
      "Already have AMAT\n",
      "Already have APTV\n",
      "Already have ADM\n",
      "Already have ANET\n",
      "Already have AJG\n",
      "Already have AIZ\n",
      "Already have T\n",
      "Already have ATO\n",
      "Already have ADSK\n",
      "Already have ADP\n",
      "Already have AZO\n",
      "Already have AVB\n",
      "Already have AVY\n",
      "Already have BKR\n",
      "Already have BLL\n",
      "Already have BAC\n",
      "Already have BK\n",
      "Already have BAX\n",
      "Already have BDX\n",
      "Already have BRK\n",
      "Already have BBY\n",
      "Already have BIO\n",
      "Already have BIIB\n",
      "Already have BLK\n",
      "Already have BA\n",
      "Already have BKNG\n",
      "Already have BWA\n",
      "Already have BXP\n",
      "Already have BSX\n",
      "Already have BMY\n",
      "Already have AVGO\n",
      "Already have BR\n",
      "Already have CHRW\n",
      "Already have COG\n",
      "Already have CDNS\n",
      "Already have CPB\n",
      "Already have COF\n",
      "Already have CAH\n",
      "Already have KMX\n",
      "Already have CCL\n",
      "Already have CAT\n",
      "Already have CBOE\n",
      "Already have CBRE\n",
      "Already have CDW\n",
      "Already have CE\n",
      "Already have CNC\n",
      "Already have CNP\n",
      "Already have CTL\n",
      "Already have CERN\n",
      "Already have CF\n",
      "Already have SCHW\n",
      "Already have CHTR\n",
      "Already have CVX\n",
      "Already have CMG\n",
      "Already have CB\n",
      "Already have CHD\n",
      "Already have CI\n",
      "Already have CINF\n",
      "Already have CTAS\n",
      "Already have CSCO\n",
      "Already have C\n",
      "Already have CFG\n",
      "Already have CTXS\n",
      "Already have CLX\n",
      "Already have CME\n",
      "Already have CMS\n",
      "Already have KO\n",
      "Already have CTSH\n",
      "Already have CL\n",
      "Already have CMCSA\n",
      "Already have CMA\n",
      "Already have CAG\n",
      "Already have CXO\n",
      "Already have COP\n",
      "Already have ED\n",
      "Already have STZ\n",
      "Already have COO\n",
      "Already have CPRT\n",
      "Already have GLW\n",
      "Already have CTVA\n",
      "Already have COST\n",
      "Already have COTY\n",
      "Already have CCI\n",
      "Already have CSX\n",
      "Already have CMI\n",
      "Already have CVS\n",
      "Already have DHI\n",
      "Already have DHR\n",
      "Already have DRI\n",
      "Already have DVA\n",
      "Already have DE\n",
      "Already have DAL\n",
      "Already have XRAY\n",
      "Already have DVN\n",
      "Already have DXCM\n",
      "Already have FANG\n",
      "Already have DLR\n",
      "Already have DFS\n",
      "Already have DISCA\n",
      "Already have DISCK\n",
      "Already have DISH\n",
      "Already have DG\n",
      "Already have DLTR\n",
      "Already have D\n",
      "Already have DPZ\n",
      "Already have DOV\n",
      "Already have DOW\n",
      "Already have DTE\n",
      "Already have DUK\n",
      "Already have DRE\n",
      "Already have DD\n",
      "Already have DXC\n",
      "Already have ETFC\n",
      "Already have EMN\n",
      "Already have ETN\n",
      "Already have EBAY\n",
      "Already have ECL\n",
      "Already have EIX\n",
      "Already have EW\n",
      "Already have EA\n",
      "Already have EMR\n",
      "Already have ETR\n",
      "Already have EOG\n",
      "Already have EFX\n",
      "Already have EQIX\n",
      "Already have EQR\n",
      "Already have ESS\n",
      "Already have EL\n",
      "Already have EVRG\n",
      "Already have ES\n",
      "Already have RE\n",
      "Already have EXC\n",
      "Already have EXPE\n",
      "Already have EXPD\n",
      "Already have EXR\n",
      "Already have XOM\n",
      "Already have FFIV\n",
      "Already have FB\n",
      "Already have FAST\n",
      "Already have FRT\n",
      "Already have FDX\n",
      "Already have FIS\n",
      "Already have FITB\n",
      "Already have FE\n",
      "Already have FRC\n",
      "Already have FISV\n",
      "Already have FLT\n",
      "Already have FLIR\n",
      "Already have FLS\n",
      "Already have FMC\n",
      "Already have F\n",
      "Already have FTNT\n",
      "Already have FTV\n",
      "Already have FBHS\n",
      "Already have FOXA\n",
      "Already have FOX\n",
      "Already have BEN\n",
      "Already have FCX\n",
      "Already have GPS\n",
      "Already have GRMN\n",
      "Already have IT\n",
      "Already have GD\n",
      "Already have GE\n",
      "Already have GIS\n",
      "Already have GM\n",
      "Already have GPC\n",
      "Already have GILD\n",
      "Already have GL\n",
      "Already have GPN\n",
      "Already have GS\n",
      "Already have GWW\n",
      "Already have HRB\n",
      "Already have HAL\n",
      "Already have HBI\n",
      "Already have HIG\n",
      "Already have HAS\n",
      "Already have HCA\n",
      "Already have PEAK\n",
      "Already have HSIC\n",
      "Already have HSY\n",
      "Already have HES\n",
      "Already have HPE\n",
      "Already have HLT\n",
      "Already have HFC\n",
      "Already have HOLX\n",
      "Already have HD\n",
      "Already have HON\n",
      "Already have HRL\n",
      "Already have HST\n",
      "Already have HWM\n",
      "Already have HPQ\n",
      "Already have HUM\n",
      "Already have HBAN\n",
      "Already have HII\n",
      "Already have IEX\n",
      "Already have IDXX\n",
      "Already have INFO\n",
      "Already have ITW\n",
      "Already have ILMN\n",
      "Already have INCY\n",
      "Already have IR\n",
      "Already have INTC\n",
      "Already have ICE\n",
      "Already have IBM\n",
      "Already have IP\n",
      "Already have IPG\n",
      "Already have IFF\n",
      "Already have INTU\n",
      "Already have ISRG\n",
      "Already have IVZ\n",
      "Already have IPGP\n",
      "Already have IQV\n",
      "Already have IRM\n",
      "Already have JKHY\n",
      "Already have J\n",
      "Already have JBHT\n",
      "Already have SJM\n",
      "Already have JNJ\n",
      "Already have JCI\n",
      "Already have JPM\n",
      "Already have JNPR\n",
      "Already have KSU\n",
      "Already have K\n",
      "Already have KEY\n",
      "Already have KEYS\n",
      "Already have KMB\n",
      "Already have KIM\n",
      "Already have KMI\n",
      "Already have KLAC\n",
      "Already have KSS\n",
      "Already have KHC\n",
      "Already have LB\n",
      "Already have LH\n",
      "Already have LRCX\n",
      "Already have LW\n",
      "Already have LVS\n",
      "Already have LEG\n",
      "Already have LDOS\n",
      "Already have LEN\n",
      "Already have LLY\n",
      "Already have LNC\n",
      "Already have LIN\n",
      "Already have LYV\n",
      "Already have LMT\n",
      "Already have L\n",
      "Already have LOW\n",
      "Already have LYB\n",
      "Already have MTB\n",
      "Already have MRO\n",
      "Already have MPC\n",
      "Already have MKTX\n",
      "Already have MAR\n",
      "Already have MMC\n",
      "Already have MLM\n",
      "Already have MAS\n",
      "Already have MA\n",
      "Already have MKC\n",
      "Already have MXIM\n",
      "Already have MCD\n",
      "Already have MCK\n",
      "Already have MDT\n",
      "Already have MRK\n",
      "Already have MET\n",
      "Already have MTD\n",
      "Already have MGM\n",
      "Already have MCHP\n",
      "Already have MU\n",
      "Already have MSFT\n",
      "Already have MAA\n",
      "Already have MHK\n",
      "Already have TAP\n",
      "Already have MDLZ\n",
      "Already have MNST\n",
      "Already have MCO\n",
      "Already have MS\n",
      "Already have MOS\n",
      "Already have MSI\n",
      "Already have MSCI\n",
      "Already have MYL\n",
      "Already have NDAQ\n",
      "Already have NOV\n",
      "Already have NTAP\n",
      "Already have NFLX\n",
      "Already have NWL\n",
      "Already have NEM\n",
      "Already have NWSA\n",
      "Already have NWS\n",
      "Already have NEE\n",
      "Already have NLSN\n",
      "Already have NKE\n",
      "Already have NI\n",
      "Already have NBL\n",
      "Already have NSC\n",
      "Already have NTRS\n",
      "Already have NLOK\n",
      "Already have NCLH\n",
      "Already have NRG\n",
      "Already have NUE\n",
      "Already have NVDA\n",
      "Already have NVR\n",
      "Already have ORLY\n",
      "Already have OXY\n",
      "Already have ODFL\n",
      "Already have OMC\n",
      "Already have OKE\n",
      "Already have ORCL\n",
      "Already have PCAR\n",
      "Already have PKG\n",
      "Already have PH\n",
      "Already have PAYX\n",
      "Already have PAYC\n",
      "Already have PYPL\n",
      "Already have PNR\n",
      "Already have PBCT\n",
      "Already have PEP\n",
      "Already have PKI\n",
      "Already have PRGO\n",
      "Already have PFE\n",
      "Already have PM\n",
      "Already have PSX\n",
      "Already have PNW\n",
      "Already have PXD\n",
      "Already have PNC\n",
      "Already have PPG\n",
      "Already have PPL\n",
      "Already have PFG\n",
      "Already have PG\n",
      "Already have PGR\n",
      "Already have PLD\n",
      "Already have PRU\n",
      "Already have PEG\n",
      "Already have PSA\n",
      "Already have PHM\n",
      "Already have PVH\n",
      "Already have QRVO\n",
      "Already have PWR\n",
      "Already have QCOM\n",
      "Already have DGX\n",
      "Already have RL\n",
      "Already have RJF\n",
      "Already have RTX\n",
      "Already have O\n",
      "Already have REG\n",
      "Already have REGN\n",
      "Already have RF\n",
      "Already have RSG\n",
      "Already have RMD\n",
      "Already have RHI\n",
      "Already have ROK\n",
      "Already have ROL\n",
      "Already have ROP\n",
      "Already have ROST\n",
      "Already have RCL\n",
      "Already have SPGI\n",
      "Already have CRM\n",
      "Already have SBAC\n",
      "Already have SLB\n",
      "Already have STX\n",
      "Already have SEE\n",
      "Already have SRE\n",
      "Already have NOW\n",
      "Already have SHW\n",
      "Already have SPG\n",
      "Already have SWKS\n",
      "Already have SLG\n",
      "Already have SNA\n",
      "Already have SO\n",
      "Already have LUV\n",
      "Already have SWK\n",
      "Already have SBUX\n",
      "Already have STT\n",
      "Already have STE\n",
      "Already have SYK\n",
      "Already have SIVB\n",
      "Already have SYF\n",
      "Already have SNPS\n",
      "Already have SYY\n",
      "Already have TMUS\n",
      "Already have TROW\n",
      "Already have TTWO\n",
      "Already have TPR\n",
      "Already have TGT\n",
      "Already have TEL\n",
      "Already have FTI\n",
      "Already have TDY\n",
      "Already have TFX\n",
      "Already have TXN\n",
      "Already have TXT\n",
      "Already have TMO\n",
      "Already have TIF\n",
      "Already have TJX\n",
      "Already have TSCO\n",
      "Already have TT\n",
      "Already have TDG\n",
      "Already have TRV\n",
      "Already have TFC\n",
      "Already have TWTR\n",
      "Already have TYL\n",
      "Already have TSN\n",
      "Already have ULTA\n",
      "Already have USB\n",
      "Already have UAA\n",
      "Already have UA\n",
      "Already have UNP\n",
      "Already have UAL\n",
      "Already have UPS\n",
      "Already have URI\n",
      "Already have UHS\n",
      "Already have UNM\n",
      "Already have VFC\n",
      "Already have VLO\n",
      "Already have VAR\n",
      "Already have VTR\n",
      "Already have VRSN\n",
      "Already have VRSK\n",
      "Already have VRTX\n",
      "Already have V\n",
      "Already have VNO\n",
      "Already have VMC\n",
      "Already have WRB\n",
      "Already have WAB\n",
      "Already have WMT\n",
      "Already have WBA\n",
      "Already have DIS\n",
      "Already have WM\n",
      "Already have WAT\n",
      "Already have WEC\n",
      "Already have WFC\n",
      "Already have WELL\n",
      "Already have WST\n",
      "Already have WDC\n",
      "Already have WU\n",
      "Already have WRK\n",
      "Already have WY\n",
      "Already have WHR\n",
      "Already have WMB\n",
      "Already have WLTW\n",
      "Already have WYNN\n",
      "Already have XEL\n",
      "Already have XRX\n",
      "Already have XLNX\n",
      "Already have XYL\n",
      "Already have YUM\n",
      "Already have ZBRA\n",
      "Already have ZBH\n",
      "Already have ZION\n",
      "Already have ZTS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRK\n",
      "BF\n",
      "2014-01-03\n",
      "2014-01-06\n",
      "2014-01-07\n",
      "2014-01-08\n",
      "2014-01-09\n",
      "2014-01-10\n",
      "2014-01-13\n",
      "2014-01-14\n",
      "2014-01-15\n",
      "2014-01-16\n",
      "2014-01-17\n",
      "2014-01-21\n",
      "2014-01-22\n",
      "2014-01-23\n",
      "2014-01-24\n",
      "2014-01-27\n",
      "2014-01-28\n",
      "2014-01-29\n",
      "2014-01-30\n",
      "2014-01-31\n",
      "2014-02-03\n",
      "2014-02-04\n",
      "2014-02-05\n",
      "2014-02-06\n",
      "2014-02-07\n",
      "2014-02-10\n",
      "2014-02-11\n",
      "2014-02-12\n",
      "2014-02-13\n",
      "2014-02-14\n",
      "2014-02-18\n",
      "2014-02-19\n",
      "2014-02-20\n",
      "2014-02-21\n",
      "2014-02-24\n",
      "2014-02-25\n",
      "2014-02-26\n",
      "2014-02-27\n",
      "2014-02-28\n",
      "2014-03-03\n",
      "2014-03-04\n",
      "2014-03-05\n",
      "2014-03-06\n",
      "2014-03-07\n",
      "2014-03-10\n",
      "2014-03-11\n",
      "2014-03-12\n",
      "2014-03-13\n",
      "2014-03-14\n",
      "2014-03-17\n",
      "2014-03-18\n",
      "2014-03-19\n",
      "2014-03-20\n",
      "2014-03-21\n",
      "2014-03-24\n",
      "2014-03-25\n",
      "2014-03-26\n",
      "2014-03-27\n",
      "2014-03-28\n",
      "2014-03-31\n",
      "2014-04-01\n",
      "2014-04-02\n",
      "2014-04-03\n",
      "2014-04-04\n",
      "2014-04-07\n",
      "2014-04-08\n",
      "2014-04-09\n",
      "2014-04-10\n",
      "2014-04-11\n",
      "2014-04-14\n",
      "2014-04-15\n",
      "2014-04-16\n",
      "2014-04-17\n",
      "2014-04-21\n",
      "2014-04-22\n",
      "2014-04-23\n",
      "2014-04-24\n",
      "2014-04-25\n",
      "2014-04-28\n",
      "2014-04-29\n",
      "2014-04-30\n",
      "2014-05-01\n",
      "2014-05-02\n",
      "2014-05-05\n",
      "2014-05-06\n",
      "2014-05-07\n",
      "2014-05-08\n",
      "2014-05-09\n",
      "2014-05-12\n",
      "2014-05-13\n",
      "2014-05-14\n",
      "2014-05-15\n",
      "2014-05-16\n",
      "2014-05-19\n",
      "2014-05-20\n",
      "2014-05-21\n",
      "2014-05-22\n",
      "2014-05-23\n",
      "2014-05-27\n",
      "2014-05-28\n",
      "2014-05-29\n",
      "2014-05-30\n",
      "2014-06-02\n",
      "2014-06-03\n",
      "2014-06-04\n",
      "2014-06-05\n",
      "2014-06-06\n",
      "2014-06-09\n",
      "2014-06-10\n",
      "2014-06-11\n",
      "2014-06-12\n",
      "2014-06-13\n",
      "2014-06-16\n",
      "2014-06-17\n",
      "2014-06-18\n",
      "2014-06-19\n",
      "2014-06-20\n",
      "2014-06-23\n",
      "2014-06-24\n",
      "2014-06-25\n",
      "2014-06-26\n",
      "2014-06-27\n",
      "2014-06-30\n",
      "2014-07-01\n",
      "2014-07-02\n",
      "2014-07-03\n",
      "2014-07-07\n",
      "2014-07-08\n",
      "2014-07-09\n",
      "2014-07-10\n",
      "2014-07-11\n",
      "2014-07-14\n",
      "2014-07-15\n",
      "2014-07-16\n",
      "2014-07-17\n",
      "2014-07-18\n",
      "2014-07-21\n",
      "2014-07-22\n",
      "2014-07-23\n",
      "2014-07-24\n",
      "2014-07-25\n",
      "2014-07-28\n",
      "2014-07-29\n",
      "2014-07-30\n",
      "2014-07-31\n",
      "2014-08-01\n",
      "2014-08-04\n",
      "2014-08-05\n",
      "2014-08-06\n",
      "2014-08-07\n",
      "2014-08-08\n",
      "2014-08-11\n",
      "2014-08-12\n",
      "2014-08-13\n",
      "2014-08-14\n",
      "2014-08-15\n",
      "2014-08-18\n",
      "2014-08-19\n",
      "2014-08-20\n",
      "2014-08-21\n",
      "2014-08-22\n",
      "2014-08-25\n",
      "2014-08-26\n",
      "2014-08-27\n",
      "2014-08-28\n",
      "2014-08-29\n",
      "2014-09-02\n",
      "2014-09-03\n",
      "2014-09-04\n",
      "2014-09-05\n",
      "2014-09-08\n",
      "2014-09-09\n",
      "2014-09-10\n",
      "2014-09-11\n",
      "2014-09-12\n",
      "2014-09-15\n",
      "2014-09-16\n",
      "2014-09-17\n",
      "2014-09-18\n",
      "2014-09-19\n",
      "2014-09-22\n",
      "2014-09-23\n",
      "2014-09-24\n",
      "2014-09-25\n",
      "2014-09-26\n",
      "2014-09-29\n",
      "2014-09-30\n",
      "2014-10-01\n",
      "2014-10-02\n",
      "2014-10-03\n",
      "2014-10-06\n",
      "2014-10-07\n",
      "2014-10-08\n",
      "2014-10-09\n",
      "2014-10-10\n",
      "2014-10-13\n",
      "2014-10-14\n",
      "2014-10-15\n",
      "2014-10-16\n",
      "2014-10-17\n",
      "2014-10-20\n",
      "2014-10-21\n",
      "2014-10-22\n",
      "2014-10-23\n",
      "2014-10-24\n",
      "2014-10-27\n",
      "2014-10-28\n",
      "2014-10-29\n",
      "2014-10-30\n",
      "2014-10-31\n",
      "2014-11-03\n",
      "2014-11-04\n",
      "2014-11-05\n",
      "2014-11-06\n",
      "2014-11-07\n",
      "2014-11-10\n",
      "2014-11-11\n",
      "2014-11-12\n",
      "2014-11-13\n",
      "2014-11-14\n",
      "2014-11-17\n",
      "2014-11-18\n",
      "2014-11-19\n",
      "2014-11-20\n",
      "2014-11-21\n",
      "2014-11-24\n",
      "2014-11-25\n",
      "2014-11-26\n",
      "2014-11-28\n",
      "2014-12-01\n",
      "2014-12-02\n",
      "2014-12-03\n",
      "2014-12-04\n",
      "2014-12-05\n",
      "2014-12-08\n",
      "2014-12-09\n",
      "2014-12-10\n",
      "2014-12-11\n",
      "2014-12-12\n",
      "2014-12-15\n",
      "2014-12-16\n",
      "2014-12-17\n",
      "2014-12-18\n",
      "2014-12-19\n",
      "2014-12-22\n",
      "2014-12-23\n",
      "2014-12-24\n",
      "2014-12-26\n",
      "2014-12-29\n",
      "2014-12-30\n",
      "2014-12-31\n",
      "2015-01-02\n",
      "2015-01-05\n",
      "2015-01-06\n",
      "2015-01-07\n",
      "2015-01-08\n",
      "2015-01-09\n",
      "2015-01-12\n",
      "2015-01-13\n",
      "2015-01-14\n",
      "2015-01-15\n",
      "2015-01-16\n",
      "2015-01-20\n",
      "2015-01-21\n",
      "2015-01-22\n",
      "2015-01-23\n",
      "2015-01-26\n",
      "2015-01-27\n",
      "2015-01-28\n",
      "2015-01-29\n",
      "2015-01-30\n",
      "2015-02-02\n",
      "2015-02-03\n",
      "2015-02-04\n",
      "2015-02-05\n",
      "2015-02-06\n",
      "2015-02-09\n",
      "2015-02-10\n",
      "2015-02-11\n",
      "2015-02-12\n",
      "2015-02-13\n",
      "2015-02-17\n",
      "2015-02-18\n",
      "2015-02-19\n",
      "2015-02-20\n",
      "2015-02-23\n",
      "2015-02-24\n",
      "2015-02-25\n",
      "2015-02-26\n",
      "2015-02-27\n",
      "2015-03-02\n",
      "2015-03-03\n",
      "2015-03-04\n",
      "2015-03-05\n",
      "2015-03-06\n",
      "2015-03-09\n",
      "2015-03-10\n",
      "2015-03-11\n",
      "2015-03-12\n",
      "2015-03-13\n",
      "2015-03-16\n",
      "2015-03-17\n",
      "2015-03-18\n",
      "2015-03-19\n",
      "2015-03-20\n",
      "2015-03-23\n",
      "2015-03-24\n",
      "2015-03-25\n",
      "2015-03-26\n",
      "2015-03-27\n",
      "2015-03-30\n",
      "2015-03-31\n",
      "2015-04-01\n",
      "2015-04-02\n",
      "2015-04-06\n",
      "2015-04-07\n",
      "2015-04-08\n",
      "2015-04-09\n",
      "2015-04-10\n",
      "2015-04-13\n",
      "2015-04-14\n",
      "2015-04-15\n",
      "2015-04-16\n",
      "2015-04-17\n",
      "2015-04-20\n",
      "2015-04-21\n",
      "2015-04-22\n",
      "2015-04-23\n",
      "2015-04-24\n",
      "2015-04-27\n",
      "2015-04-28\n",
      "2015-04-29\n",
      "2015-04-30\n",
      "2015-05-01\n",
      "2015-05-04\n",
      "2015-05-05\n",
      "2015-05-06\n",
      "2015-05-07\n",
      "2015-05-08\n",
      "2015-05-11\n",
      "2015-05-12\n",
      "2015-05-13\n",
      "2015-05-14\n",
      "2015-05-15\n",
      "2015-05-18\n",
      "2015-05-19\n",
      "2015-05-20\n",
      "2015-05-21\n",
      "2015-05-22\n",
      "2015-05-26\n",
      "2015-05-27\n",
      "2015-05-28\n",
      "2015-05-29\n",
      "2015-06-01\n",
      "2015-06-02\n",
      "2015-06-03\n",
      "2015-06-04\n",
      "2015-06-05\n",
      "2015-06-08\n",
      "2015-06-09\n",
      "2015-06-10\n",
      "2015-06-11\n",
      "2015-06-12\n",
      "2015-06-15\n",
      "2015-06-16\n",
      "2015-06-17\n",
      "2015-06-18\n",
      "2015-06-19\n",
      "2015-06-22\n",
      "2015-06-23\n",
      "2015-06-24\n",
      "2015-06-25\n",
      "2015-06-26\n",
      "2015-06-29\n",
      "2015-06-30\n",
      "2015-07-01\n",
      "2015-07-02\n",
      "2015-07-06\n",
      "2015-07-07\n",
      "2015-07-08\n",
      "2015-07-09\n",
      "2015-07-10\n",
      "2015-07-13\n",
      "2015-07-14\n",
      "2015-07-15\n",
      "2015-07-16\n",
      "2015-07-17\n",
      "2015-07-20\n",
      "2015-07-21\n",
      "2015-07-22\n",
      "2015-07-23\n",
      "2015-07-24\n",
      "2015-07-27\n",
      "2015-07-28\n",
      "2015-07-29\n",
      "2015-07-30\n",
      "2015-07-31\n",
      "2015-08-03\n",
      "2015-08-04\n",
      "2015-08-05\n",
      "2015-08-06\n",
      "2015-08-07\n",
      "2015-08-10\n",
      "2015-08-11\n",
      "2015-08-12\n",
      "2015-08-13\n",
      "2015-08-14\n",
      "2015-08-17\n",
      "2015-08-18\n",
      "2015-08-19\n",
      "2015-08-20\n",
      "2015-08-21\n",
      "2015-08-24\n",
      "2015-08-25\n",
      "2015-08-26\n",
      "2015-08-27\n",
      "2015-08-28\n",
      "2015-08-31\n",
      "2015-09-01\n",
      "2015-09-02\n",
      "2015-09-03\n",
      "2015-09-04\n",
      "2015-09-08\n",
      "2015-09-09\n",
      "2015-09-10\n",
      "2015-09-11\n",
      "2015-09-14\n",
      "2015-09-15\n",
      "2015-09-16\n",
      "2015-09-17\n",
      "2015-09-18\n",
      "2015-09-21\n",
      "2015-09-22\n",
      "2015-09-23\n",
      "2015-09-24\n",
      "2015-09-25\n",
      "2015-09-28\n",
      "2015-09-29\n",
      "2015-09-30\n",
      "2015-10-01\n",
      "2015-10-02\n",
      "2015-10-05\n",
      "2015-10-06\n",
      "2015-10-07\n",
      "2015-10-08\n",
      "2015-10-09\n",
      "2015-10-12\n",
      "2015-10-13\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import datetime as dt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import pickle\n",
    "import requests\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Use beautifulSoup to get the S&P 500 tickers and store it in pickle\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tickers, f)\n",
    "    return tickers\n",
    "\n",
    "def get_data_from_yahoo(reload_sp500=False):\n",
    "    #Open pickle\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "    #Read stock data from yahoo\n",
    "    start = dt.datetime(2012, 1, 1)\n",
    "    end = dt.datetime(2020,1, 1)\n",
    "    for ticker in tickers: \n",
    "        if '.' in ticker:\n",
    "            array=ticker.split(\".\")\n",
    "            ticker= array[0]\n",
    "        ticker = ticker.rstrip(\"\\n\")\n",
    "        if ticker == 'CARR' or ticker == 'KR'or ticker == 'LHX'or ticker == 'LKQ' or ticker == 'NOC' or ticker == 'OTIS'or ticker == 'UDR' or ticker == 'UNH'or ticker == 'VZ'or ticker == 'VIAC' or ticker == 'BF':\n",
    "            continue\n",
    "        if not os.path.exists('stock_dfs\\{}.csv'.format(ticker.rstrip(\"\\n\"))):\n",
    "            df = web.DataReader(ticker.rstrip(\"\\n\"), start=start, end=end, data_source='yahoo')\n",
    "            df.reset_index(inplace=True)\n",
    "            df.set_index(\"Date\", inplace=True)\n",
    "            df.to_csv('stock_dfs\\{}.csv'.format(ticker.rstrip(\"\\n\")))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "#Get Adj Close data for each stock and merge the data to one dataframe\n",
    "def data_Cleaning():\n",
    "    dataAll = []\n",
    "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "    for ticker in tickers:\n",
    "        if '.' in ticker:\n",
    "            array=ticker.split(\".\")            \n",
    "            ticker= array[0]\n",
    "            print(ticker)\n",
    "        ticker= ticker.rstrip(\"\\n\")  \n",
    "        if ticker == 'CARR' or ticker == 'KR'or ticker == 'LHX'or ticker == 'LKQ' or ticker == 'NOC' or ticker == 'OTIS'or ticker == 'UDR' or ticker == 'UNH'or ticker == 'VZ'or ticker == 'VIAC'or ticker == 'BF':\n",
    "            continue\n",
    "        data = pd.read_csv('stock_dfs\\{}.csv'.format(ticker))\n",
    "        if (ticker=='B'):\n",
    "            print(data.head())\n",
    "        data = data.set_index('Date')\n",
    "        data = data[['Adj Close']].dropna()\n",
    "        data = data.rename({\"Adj Close\": ticker},axis='columns')\n",
    "        dataAll.append(data)\n",
    "    dataAll=pd.concat(dataAll,axis = 1)\n",
    "    return dataAll\n",
    "\n",
    "#Get stock returns from given stock prices\n",
    "def getReturn(price):\n",
    "    ret = (price - price.shift(1))/price\n",
    "    ret = ret.drop(ret.index[0])\n",
    "    ret = ret.fillna(value = 0)\n",
    "    return ret\n",
    "\n",
    "#Calculate Zscores givieng a range of returns\n",
    "def getZscores(return_in_range, num_factor):\n",
    "    # Sample data for PCA (smooth it using np.log function)\n",
    "    sample = return_in_range.replace([np.inf, -np.inf], np.nan)\n",
    "    sample = sample.dropna(axis = 1,thresh = len(sample)-30)\n",
    "    mean = sample.mean() \n",
    "    sample = (sample - mean)/sample.std()# Center it column-wise\n",
    "\n",
    "    # Fit the PCA model for sample data\n",
    "    sample = pd.DataFrame(sample).fillna(0)\n",
    "    model = PCA().fit(sample)\n",
    "    weights = pd.DataFrame(model.components_)\n",
    "    # Get the first n_components factors\n",
    "    factors = np.dot(sample, weights.T)[:,:(num_factor-1)]\n",
    "    # Add 1's to fit the linear regression (intercept)\n",
    "    factors = sm.add_constant(factors)\n",
    "    # Train Ordinary Least Squares linear model for each stock\n",
    "    OLSmodels = {ticker: sm.OLS(sample[ticker], factors).fit() for ticker in sample.columns}\n",
    "    # Get the residuals from the linear regression after PCA for each stock\n",
    "    resids = pd.DataFrame({ticker: model.resid for ticker, model in OLSmodels.items()})\n",
    "    # Get the Z scores by standarize\n",
    "    zscores = ((resids - resids.mean()) / resids.std()).iloc[-1] # residuals of the most recent day\n",
    "    return zscores\n",
    "\n",
    "#Using slicing windown to get Zscores Array\n",
    "def zscoresArr(stopTime, dataAll,num_factor):\n",
    "    zscoresArr = []\n",
    "    for t in range(stopTime, len(dataAll)-stopTime-1):\n",
    "        price_in_range = dataAll[t-1:t+stopTime]\n",
    "        return_in_range = getReturn(price_in_range)\n",
    "        zscores = getZscores(return_in_range, num_factor)\n",
    "        zscoresArr.append(zscores.to_frame())\n",
    "    zscoresRes = pd.concat(zscoresArr,axis=1)     \n",
    "    return zscoresRes\n",
    "\n",
    "def backtesting(zscores, price, signals):\n",
    "    [ss, sb, cs, cb]=signals\n",
    "    #initialize original stock position\n",
    "    position = pd.Series(0, index = price.columns) \n",
    "    #initialize money, stockValue and total Value (which is the sum of money and stockValue)\n",
    "    money = pd.Series(0, index = price.index)\n",
    "    stockValue = pd.Series(0, index = price.index)\n",
    "    totalValue = pd.Series(0, index = price.index)\n",
    "    for i in zscores:\n",
    "        print(i)\n",
    "        #get the sell positions, if the zscores are higher than start sell signal\n",
    "        sell = zscores[i].where(zscores[i] >ss, 0)\n",
    "        # scaled to make sure that the weights add up to -100%\n",
    "        sell = sell/sell.sum() \n",
    "        # selling stock would increase the money \n",
    "        money[i] += sum(sell * price.loc[i])\n",
    "        # update positions\n",
    "        position = position - sell\n",
    "        \n",
    "        #get the sell positions, if the zscores are higher than start sell signal\n",
    "        buy = zscores[i].where(zscores[i] <sb, 0)\n",
    "        # scaled to make sure that the weights add up to 100%\n",
    "        buy = buy/buy.sum() \n",
    "        # buying stock would decrease the money\n",
    "        money[i] -= sum(buy * price.loc[i]) \n",
    "        # update positions\n",
    "        position = position + buy\n",
    "        \n",
    "        #get the clear positions, if the zscores are in between the close buy and close sell signals\n",
    "        clear = zscores[i].where(zscores[i].between(cb,cs), 0)\n",
    "        clear = clear.where(clear!=0, 1) #build a boolen mask for positions to clear\n",
    "        positionToClear = position * clear\n",
    "        #clear the positions, money value will change according to the positions\n",
    "        money[i] += sum(positionToClear * price.loc[i])\n",
    "        #update positions\n",
    "        position = zscores[i].where(zscores[i].between(cb,cs), 0)\n",
    "        \n",
    "        #update stockValue and totalValue\n",
    "        stockValue[i] = sum(position * price.loc[i])\n",
    "        totalValue[i] = money[i] + stockValue[i] \n",
    "    return money, stockValue, totalValue\n",
    "\n",
    "def find_Sharpe_Ratio(pnl,r):\n",
    "    ret = getReturn(pnl)\n",
    "    ret = find_Return(pnl)\n",
    "    std = ret.std() * math.sqrt(252)\n",
    "    return (mean - r)/std\n",
    "\n",
    "def find_Maximum_Drawdown(pnl):\n",
    "    ret = find_Return(pnl)\n",
    "    r = ret.add(1).cumprod()\n",
    "    dd = r.div(r.cummax()).sub(1)\n",
    "    mdd = dd.min()\n",
    "    end = dd.argmin()\n",
    "    start = r.argmax()\n",
    "    return mdd\n",
    "\n",
    "def find_Cumulative_Return(pnl):\n",
    "    return (pnl.iloc[len(pnl.index)-1] - pnl.iloc[0]) / pnl.iloc[0]\n",
    "\n",
    "def main():\n",
    "    stopTime = 252 #for slicing window\n",
    "    num_factor = 10\n",
    "    ss = 1.25 #start to sell signal\n",
    "    sb = -1.25 #start to buy signal\n",
    "    cs = 0.25 #close to sell signal\n",
    "    cb = -0.25 #close to buy signal\n",
    "    r = 0.01 #market rate\n",
    "    signals = [ss, sb, cs, cb]\n",
    "    \n",
    "    get_data_from_yahoo()\n",
    "    dataAll= data_Cleaning()\n",
    "    zscores = zscoresArr(stopTime, dataAll.fillna(0),num_factor) \n",
    "    money, stockValue, totalValue = backtesting(zscores, dataAll.fillna(0), signals)\n",
    "    #Calculation resultsd\n",
    "    sharpe_ratio = find_Sharpe_Ratio(totalValue,r)\n",
    "    maximum_drawdowns = find_Maximum_Drawdown(totalValue)\n",
    "    cumulative_return = find_Cumulative_Return(totalValue)\n",
    "    print('Cumulative return:', cumulative_return, 'Sharpe_Ratio:', sharpe_Ratio, 'Maximum_drawdowns: ',maximum_drawdowns)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()    \n",
    "    \n",
    "    \n",
    "#Reference:\n",
    "#Reading the yahoo data https://pythonprogramming.net/sp500-company-price-data-python-programming-for-finance/\n",
    "#PCA strategy https://www.quantconnect.com/tutorials/strategy-library/mean-reversion-statistical-arbitrage-strategy-in-stocks\n",
    "#Calculation results https://github.com/YuxiLiuAsana/Statistical-Arbitrage-Avellaneda-/blob/master/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
